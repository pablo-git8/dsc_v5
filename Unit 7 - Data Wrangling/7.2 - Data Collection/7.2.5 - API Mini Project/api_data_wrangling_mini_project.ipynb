{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise will require you to pull some data from https://data.nasdaq.com/ (formerly Quandl API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, you will need to register a free account on the https://data.nasdaq.com/ website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you register, you will be provided with a unique API key, that you should store:\n",
    "\n",
    "*Note*: Use a `.env` file and put your key in there and `python-dotenv` to access it in this notebook. \n",
    "\n",
    "The code below uses a key that was used when generating this project but has since been deleted. Never submit your keys to source control. There is a `.env-example` file in this repository to illusrtate what you need. Copy that to a file called `.env` and use your own api key in that `.env` file. Make sure you also have a `.gitignore` file with a line for `.env` added to it. \n",
    "\n",
    "The standard Python gitignore is [here](https://github.com/github/gitignore/blob/master/Python.gitignore) you can just copy that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get api key from your .env file\n",
    "import os\n",
    "import dotenv\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "#load_dotenv()\n",
    "load_dotenv('../NASDAQ_API_KEY.env')\n",
    "API_KEY = os.getenv('NASDAQ_API_KEY')\n",
    "\n",
    "#print(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nasdaq Data has a large number of data sources, but, unfortunately, most of them require a Premium subscription. Still, there are also a good number of free datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this mini project, we will focus on equities data from the Frankfurt Stock Exhange (FSE), which is available for free. We'll try and analyze the stock prices of a company called Carl Zeiss Meditec, which manufactures tools for eye examinations, as well as medical lasers for laser eye surgery: https://www.zeiss.com/meditec/int/home.html. The company is listed under the stock ticker AFX_X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the detailed Nasdaq Data API instructions here: https://docs.data.nasdaq.com/docs/in-depth-usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there is a dedicated Python package for connecting to the Nasdaq API, we would prefer that you use the *requests* package, which can be easily downloaded using *pip* or *conda*. You can find the documentation for the package here: http://docs.python-requests.org/en/master/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, apart from the *requests* package, you are encouraged to not use any third party Python packages, such as *pandas*, and instead focus on what's available in the Python Standard Library (the *collections* module might come in handy: https://pymotw.com/3/collections/).\n",
    "Also, since you won't have access to DataFrames, you are encouraged to use Python's native data structures - preferably dictionaries, though some questions can also be answered using lists.\n",
    "You can read more on these data structures here: https://docs.python.org/3/tutorial/datastructures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the JSON responses you will be getting from the API map almost one-to-one to Python's dictionaries. Unfortunately, they can be very nested, so make sure you read up on indexing dictionaries in the documentation provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the relevant modules\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: API's can change a bit with each version, for this exercise it is reccomended to use the nasdaq api at `https://data.nasdaq.com/api/v3/`. This is the same api as what used to be quandl so `https://www.quandl.com/api/v3/` should work too.\n",
    "\n",
    "Hint: We are looking for the `AFX_X` data on the `datasets/FSE/` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, call the Nasdaq API and pull out a small sample of the data (only one day) to get a glimpse\n",
    "# into the JSON structure that will be returned\n",
    "\n",
    "#GET https://data.nasdaq.com/api/v3/datasets/{database_code}/{dataset_code}/data.{return_format}\n",
    "url = \"https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X/data.json?api_key={}\".format(API_KEY)\n",
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['dataset_data'])\n"
     ]
    }
   ],
   "source": [
    "# Inspect the JSON structure of the object you created, and take note of how nested it is,\n",
    "# as well as the overall structure\n",
    "\n",
    "json_data = r.json()\n",
    "#Getting an overall picture of the structure of the json\n",
    "print(json_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['limit', 'transform', 'column_index', 'column_names', 'start_date', 'end_date', 'frequency', 'data', 'collapse', 'order'])\n"
     ]
    }
   ],
   "source": [
    "#A single key ('dataset_data') dictionary with 10 nested keys\n",
    "print(json_data['dataset_data'].keys())\n",
    "j_data = json_data['dataset_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date',\n",
       " 'Open',\n",
       " 'High',\n",
       " 'Low',\n",
       " 'Close',\n",
       " 'Change',\n",
       " 'Traded Volume',\n",
       " 'Turnover',\n",
       " 'Last Price of the Day',\n",
       " 'Daily Traded Units',\n",
       " 'Daily Turnover']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exploring the columns (features) available\n",
    "j_data['column_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-12-01',\n",
       " 112.2,\n",
       " 112.2,\n",
       " 111.5,\n",
       " 112.0,\n",
       " None,\n",
       " 51.0,\n",
       " 5703.0,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example of a daily record of Carl Zeiss Meditec stock in the Frankfurt Stock Exhange (FSE) \n",
    "j_data['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020\n"
     ]
    }
   ],
   "source": [
    "#Converting the key as a datetime object\n",
    "d = datetime.strptime(j_data['data'][0][0], '%Y-%m-%d')\n",
    "print(d.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are your tasks for this mini project:\n",
    "\n",
    "**1. Collect data from the Franfurt Stock Exchange, for the ticker AFX_X, for the whole year 2017 (keep in mind that the date format is YYYY-MM-DD).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_2017 = []\n",
    "for i in j_data['data']:\n",
    "    year = datetime.strptime(i[0], '%Y-%m-%d').year\n",
    "    #Select only records from 2017 in a list\n",
    "    if year == 2017:\n",
    "        d_2017.append(i)\n",
    "#print(d_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Convert the returned JSON object into a Python dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the 2017 record list to a dictionary\n",
    "data_2017 = {x[0]: x[1:] for x in d_2017}\n",
    "#print(data_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Calculate what the highest and lowest opening prices were for the stock in this period.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The highest opening price in 2017 was: 53.11 USD\n"
     ]
    }
   ],
   "source": [
    "open_p = [] #List for gwtting the opening prices\n",
    "diff_close = [] #List for getting the difference between two days\n",
    "avg_dvol = [] #List for getting the average daily volume\n",
    "for i in data_2017.keys():\n",
    "    if data_2017[i][0] != None:\n",
    "        open_p.append(data_2017[i][0])\n",
    "    diff_close.append(data_2017[i][3])\n",
    "    avg_dvol.append(data_2017[i][5])\n",
    "print('The highest opening price in 2017 was: {} USD'.format(max(open_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What was the largest change in any one day (based on High and Low price)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest opening price in 2017 was: 34.0 USD\n"
     ]
    }
   ],
   "source": [
    "print('The lowest opening price in 2017 was: {} USD'.format(min(open_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. What was the largest change between any two days (based on Closing Price)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The largest change between any two days was: 2.56 USD\n"
     ]
    }
   ],
   "source": [
    "lar_diff = []\n",
    "for i in range(len(diff_close)-1):\n",
    "    lar_diff.append(abs(diff_close[i+1]-diff_close[i]))\n",
    "print('The largest change between any two days was: {:.2f} USD'.format(max(lar_diff)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. What was the average daily trading volume during this year?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avergae trading volume in 2017 was: 89124.34\n"
     ]
    }
   ],
   "source": [
    "print('The avergae trading volume in 2017 was: {:.2f}'.format(np.mean(avg_dvol)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. (Optional) What was the median trading volume during this year. (Note: you may need to implement your own function for calculating the median.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average trading volume in 2017 was: 76286.00\n"
     ]
    }
   ],
   "source": [
    "print('The average trading volume in 2017 was: {:.2f}'.format(np.median(avg_dvol)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7635eb1b9d0fe97add78a7368b6b431c09bb8ad5c42e437d64abdd99821c31ae"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
